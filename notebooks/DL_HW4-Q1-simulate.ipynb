{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "67ZNLgRPmy-V",
      "metadata": {
        "id": "67ZNLgRPmy-V"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5707e43d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8d483be2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== Assignment Hyperparameters ==========\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "SEQ_LEN = 1024\n",
        "VOCAB_SIZE = 1000\n",
        "EMBED_SIZE = 512\n",
        "HIDDEN_SIZE = 768\n",
        "NUM_HEADS = 8\n",
        "ENCODER_LAYERS = 2\n",
        "DECODER_LAYERS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "90217d23",
      "metadata": {
        "id": "90217d23"
      },
      "outputs": [],
      "source": [
        "# ========= Embedding & Positional Encoding =======\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=4096):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)].to(x.device)\n",
        "\n",
        "embedding = nn.Embedding(VOCAB_SIZE, EMBED_SIZE)\n",
        "pos_encoding = PositionalEncoding(EMBED_SIZE, SEQ_LEN)\n",
        "\n",
        "# ========== Encoder Block ==========\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, emb_dim, hidden_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.mha = nn.MultiheadAttention(emb_dim, num_heads, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(emb_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, emb_dim)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "    def forward(self, x, layer_num=0):\n",
        "        # Multi-Head Attention (self-attention)\n",
        "        attn_out, _ = self.mha(x, x, x)\n",
        "        print(f\"Encoder Layer {layer_num}: after MHA:\", attn_out.shape)\n",
        "        x = self.norm1(x + attn_out)\n",
        "        print(f\"Encoder Layer {layer_num}: after Add+Norm1:\", x.shape)\n",
        "        # Feed Forward\n",
        "        ffn_out = self.ffn(x)\n",
        "        print(f\"Encoder Layer {layer_num}: after FFN:\", ffn_out.shape)\n",
        "        x = self.norm2(x + ffn_out)\n",
        "        print(f\"Encoder Layer {layer_num}: after Add+Norm2:\", x.shape)\n",
        "        return x\n",
        "\n",
        "    def parameter_count(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "# ========== Decoder Block ==========\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, emb_dim, hidden_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.mha1 = nn.MultiheadAttention(emb_dim, num_heads, batch_first=True)  # Masked Self-Attention\n",
        "        self.norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.mha2 = nn.MultiheadAttention(emb_dim, num_heads, batch_first=True)  # Encoder-Decoder Attention\n",
        "        self.norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(emb_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, emb_dim)\n",
        "        )\n",
        "        self.norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "    def forward(self, x, enc_out, layer_num=0):\n",
        "        # Masked Self-Attention (for real generation, you must use masking here)\n",
        "        attn1_out, _ = self.mha1(x, x, x)\n",
        "        print(f\"Decoder Layer {layer_num}: after Masked MHA:\", attn1_out.shape)\n",
        "        x = self.norm1(x + attn1_out)\n",
        "        print(f\"Decoder Layer {layer_num}: after Add+Norm1:\", x.shape)\n",
        "        # Encoder-Decoder Attention\n",
        "        attn2_out, _ = self.mha2(x, enc_out, enc_out)\n",
        "        print(f\"Decoder Layer {layer_num}: after Enc-Dec MHA:\", attn2_out.shape)\n",
        "        x = self.norm2(x + attn2_out)\n",
        "        print(f\"Decoder Layer {layer_num}: after Add+Norm2:\", x.shape)\n",
        "        # Feed Forward\n",
        "        ffn_out = self.ffn(x)\n",
        "        print(f\"Decoder Layer {layer_num}: after FFN:\", ffn_out.shape)\n",
        "        x = self.norm3(x + ffn_out)\n",
        "        print(f\"Decoder Layer {layer_num}: after Add+Norm3:\", x.shape)\n",
        "        return x\n",
        "\n",
        "    def parameter_count(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "# ========== Encoder Stack ==========\n",
        "class EncoderStack(nn.Module):\n",
        "    def __init__(self, num_layers, emb_dim, hidden_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderBlock(emb_dim, hidden_dim, num_heads) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            print(f\"\\n--- Encoder Block {i+1} ---\")\n",
        "            x = layer(x, layer_num=i+1)\n",
        "        return x\n",
        "\n",
        "    def parameter_count(self):\n",
        "        return sum(block.parameter_count() for block in self.layers)\n",
        "\n",
        "# ========== Decoder Stack ==========\n",
        "class DecoderStack(nn.Module):\n",
        "    def __init__(self, num_layers, emb_dim, hidden_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderBlock(emb_dim, hidden_dim, num_heads) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, enc_out):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            print(f\"\\n--- Decoder Block {i+1} ---\")\n",
        "            x = layer(x, enc_out, layer_num=i+1)\n",
        "        return x\n",
        "\n",
        "    def parameter_count(self):\n",
        "        return sum(block.parameter_count() for block in self.layers)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Ky7vid0ej3zb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky7vid0ej3zb",
        "outputId": "8d03b828-adbc-422d-9e96-0ce4a1ec69b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After embedding: torch.Size([32, 1024, 512])\n",
            "After positional encoding: torch.Size([32, 1024, 512])\n",
            "\n",
            "=== EncoderStack: Total parameters: 3,680,768\n",
            "\n",
            "--- Encoder Block 1 ---\n",
            "Encoder Layer 1: after MHA: torch.Size([32, 1024, 512])\n",
            "Encoder Layer 1: after Add+Norm1: torch.Size([32, 1024, 512])\n",
            "Encoder Layer 1: after FFN: torch.Size([32, 1024, 512])\n",
            "Encoder Layer 1: after Add+Norm2: torch.Size([32, 1024, 512])\n",
            "\n",
            "--- Encoder Block 2 ---\n",
            "Encoder Layer 2: after MHA: torch.Size([32, 1024, 512])\n",
            "Encoder Layer 2: after Add+Norm1: torch.Size([32, 1024, 512])\n",
            "Encoder Layer 2: after FFN: torch.Size([32, 1024, 512])\n",
            "Encoder Layer 2: after Add+Norm2: torch.Size([32, 1024, 512])\n",
            "\n",
            "=== DecoderStack: Total parameters: 8,676,096\n",
            "\n",
            "--- Decoder Block 1 ---\n",
            "Decoder Layer 1: after Masked MHA: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 1: after Add+Norm1: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 1: after Enc-Dec MHA: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 1: after Add+Norm2: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 1: after FFN: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 1: after Add+Norm3: torch.Size([32, 1024, 512])\n",
            "\n",
            "--- Decoder Block 2 ---\n",
            "Decoder Layer 2: after Masked MHA: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 2: after Add+Norm1: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 2: after Enc-Dec MHA: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 2: after Add+Norm2: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 2: after FFN: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 2: after Add+Norm3: torch.Size([32, 1024, 512])\n",
            "\n",
            "--- Decoder Block 3 ---\n",
            "Decoder Layer 3: after Masked MHA: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 3: after Add+Norm1: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 3: after Enc-Dec MHA: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 3: after Add+Norm2: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 3: after FFN: torch.Size([32, 1024, 512])\n",
            "Decoder Layer 3: after Add+Norm3: torch.Size([32, 1024, 512])\n"
          ]
        }
      ],
      "source": [
        "# ========== Demo: Forward Pass & Parameter Reporting ==========\n",
        "# Fake input data (like token indices)\n",
        "x = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN))\n",
        "\n",
        "# Embedding and positional encoding\n",
        "out = embedding(x)\n",
        "print(\"After embedding:\", out.shape)\n",
        "out = pos_encoding(out)\n",
        "print(\"After positional encoding:\", out.shape)\n",
        "\n",
        "# Encoder stack\n",
        "encoder = EncoderStack(ENCODER_LAYERS, EMBED_SIZE, HIDDEN_SIZE, NUM_HEADS)\n",
        "print(f\"\\n=== EncoderStack: Total parameters: {encoder.parameter_count():,}\")\n",
        "enc_out = encoder(out)\n",
        "\n",
        "# Decoder stack (uses a copy of input for simplicity)\n",
        "dec_in = embedding(x)\n",
        "dec_in = pos_encoding(dec_in)\n",
        "decoder = DecoderStack(DECODER_LAYERS, EMBED_SIZE, HIDDEN_SIZE, NUM_HEADS)\n",
        "print(f\"\\n=== DecoderStack: Total parameters: {decoder.parameter_count():,}\")\n",
        "dec_out = decoder(dec_in, enc_out)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "67ZNLgRPmy-V",
        "pkqBIn1E8kic",
        "wUpD6jl18egT",
        "izhF8zsCCRVp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cudatest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
